{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "----------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Neural Network, we have initialized the weights randomly. Use a training sample\n",
    "(X,y) = ((1,1), 0) to update the weights (perform one round of backpropagation using one training\n",
    "sample). Use learning rate parameter alpha = 0.1. Note that we have bias terms with value of -1 in\n",
    "this network (no need for coding for this question).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See pdf attached in CSNS: hw2_problem1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Adjusting the hyperparameters of MNIST Digit Recognition using ANN model in Keras+TensorFlow and Grid-Search in SciKitLearn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sequential\" models let usv define a stack of neural network layers\n",
    "from keras.models import Sequential\n",
    "# import the core layers:\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some utilities to transform/preprocess our data:\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a - Download the Kears+Tensorflow tutorial from CSNS. Import all required modules including the following:\n",
    "`from keras.wrappers.scikit_learn import KerasClassifier`\n",
    "`from sklearn.model_selection import GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b - Import the minst dataset, and split it into testing and training as we saw in the tutorial. Then, reshape each sample into a row vector, and scale it by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Keras will download MNIST digit dataset for us:\n",
    "from keras.datasets import mnist\n",
    " \n",
    "# By default, the first 60k of MNIST has been defined as training and the rest as testing set: \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the the pixels into a line:\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply scale the features to the range of [0,1]:\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# output label:\n",
    "print (y_train.shape)\n",
    "print (y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c - Perform OneHotEncoding for the label y. So, your label will be a vector of 10 elements for each data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Label after OneHotEncoding:\n",
    "print (y_train.shape)\n",
    "print (y_train[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## d - Now, define a function called model_creator. This function will define, create, and compile your neural network model according to your structure, and then return the built model as the output. For the ANN neurons/layers, use the same structure as we had in the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(input_size=784, hidden_neurons=100, out_size=10):\n",
    "    # define:\n",
    "    model = Sequential()\n",
    "    \n",
    "    # second layer: hidden layer:\n",
    "    model.add(Dense(hidden_neurons, input_dim = input_size))  # Nuerons\n",
    "    model.add(Activation('sigmoid')) # Activation\n",
    "    \n",
    "    # third layer: output layer:\n",
    "    model.add(Dense(out_size, input_dim = hidden_neurons))  # Nuerons\n",
    "    model.add(Activation('softmax')) # Activation\n",
    "    \n",
    "    # compile:\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # return:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_neurons = 100\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e - Fix the random state for reproducibility:\n",
    "\n",
    "`seed = 2, np.random.seed(seed)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f - Use KerasClassifier class to wrap your model as an object:\n",
    "\n",
    "`model = KerasClassifier(build_fn = model_creator, verbose=2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = model_creator, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g - Now, run sklearn GridSearch to find the best `batch_size` and `epochs`. Search in this range: `batch_size = [30 , 50 , 100 ]` , `epochs = [10, 15, 20]`.\n",
    "\n",
    "In your GridSearch, the estimator is the above model, the scoring should be 'neg_log_loss', and you have to use 10-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [30, 50, 100]\n",
    "epochs = [10, 15, 20]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=10,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.8872 - acc: 0.8085\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.3841 - acc: 0.9005\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2939 - acc: 0.9214\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2467 - acc: 0.9307\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2154 - acc: 0.9394\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.1872 - acc: 0.9473\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.1679 - acc: 0.9529\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.1487 - acc: 0.9578\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.1324 - acc: 0.9647\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.1185 - acc: 0.9677\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.1059 - acc: 0.9718\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0937 - acc: 0.9760\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0847 - acc: 0.9791\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0753 - acc: 0.9822\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0665 - acc: 0.9857\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0589 - acc: 0.9878\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0521 - acc: 0.9891\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0460 - acc: 0.9910\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0406 - acc: 0.9931\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0356 - acc: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x13c188630>,\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'batch_size': [30, 50, 100], 'epochs': [10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h - Based on your results, what is the best batch_size and epochs? Now, test your model with the best batch_size and epochs on the testing set. `grid.best_estimator_.model` gives you the best model found and trained in the gridsearch. What is the prediction accuracy on the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best batch_size and epochs: {'batch_size': 30, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest batch_size and epochs:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40199 samples, validate on 19801 samples\n",
      "Epoch 1/20\n",
      "40199/40199 [==============================] - 3s 65us/step - loss: 0.1585 - acc: 0.9526 - val_loss: 0.1394 - val_acc: 0.9591\n",
      "Epoch 2/20\n",
      "40199/40199 [==============================] - 3s 65us/step - loss: 0.1126 - acc: 0.9669 - val_loss: 0.1231 - val_acc: 0.9646\n",
      "Epoch 3/20\n",
      "40199/40199 [==============================] - 3s 67us/step - loss: 0.0922 - acc: 0.9737 - val_loss: 0.1196 - val_acc: 0.9642\n",
      "Epoch 4/20\n",
      "40199/40199 [==============================] - 3s 66us/step - loss: 0.0783 - acc: 0.9776 - val_loss: 0.1102 - val_acc: 0.9671\n",
      "Epoch 5/20\n",
      "40199/40199 [==============================] - 3s 64us/step - loss: 0.0659 - acc: 0.9824 - val_loss: 0.1058 - val_acc: 0.9686\n",
      "Epoch 6/20\n",
      "40199/40199 [==============================] - 3s 65us/step - loss: 0.0567 - acc: 0.9846 - val_loss: 0.1019 - val_acc: 0.9702\n",
      "Epoch 7/20\n",
      "40199/40199 [==============================] - 3s 67us/step - loss: 0.0493 - acc: 0.9873 - val_loss: 0.0991 - val_acc: 0.9706\n",
      "Epoch 8/20\n",
      "40199/40199 [==============================] - 3s 68us/step - loss: 0.0417 - acc: 0.9899 - val_loss: 0.0951 - val_acc: 0.9713\n",
      "Epoch 9/20\n",
      "40199/40199 [==============================] - 3s 68us/step - loss: 0.0361 - acc: 0.9915 - val_loss: 0.0977 - val_acc: 0.9716\n",
      "Epoch 10/20\n",
      "40199/40199 [==============================] - 3s 68us/step - loss: 0.0309 - acc: 0.9935 - val_loss: 0.0969 - val_acc: 0.9713\n",
      "Epoch 11/20\n",
      "40199/40199 [==============================] - 3s 66us/step - loss: 0.0262 - acc: 0.9950 - val_loss: 0.0970 - val_acc: 0.9721\n",
      "Epoch 12/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0227 - acc: 0.9957 - val_loss: 0.0982 - val_acc: 0.9711\n",
      "Epoch 13/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0190 - acc: 0.9969 - val_loss: 0.0961 - val_acc: 0.9726\n",
      "Epoch 14/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0163 - acc: 0.9977 - val_loss: 0.0973 - val_acc: 0.9714\n",
      "Epoch 15/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0137 - acc: 0.9984 - val_loss: 0.0952 - val_acc: 0.9729\n",
      "Epoch 16/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0117 - acc: 0.9987 - val_loss: 0.1000 - val_acc: 0.9723\n",
      "Epoch 17/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.0967 - val_acc: 0.9729\n",
      "Epoch 18/20\n",
      "40199/40199 [==============================] - 3s 63us/step - loss: 0.0083 - acc: 0.9994 - val_loss: 0.0989 - val_acc: 0.9725\n",
      "Epoch 19/20\n",
      "40199/40199 [==============================] - 3s 66us/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0995 - val_acc: 0.9728\n",
      "Epoch 20/20\n",
      "40199/40199 [==============================] - 3s 64us/step - loss: 0.0057 - acc: 0.9996 - val_loss: 0.0995 - val_acc: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1476bd748>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_.model\n",
    "\n",
    "# doesn't take random_seed?\n",
    "best_model.fit(X_train, y_train, validation_split=0.33, batch_size=30, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing, Prediction, Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/step\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Prediction:\n",
    "y_predict = best_model.predict(X_test, verbose=1)\n",
    "print (y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Test accuracy is:  0.9828\n"
     ]
    }
   ],
   "source": [
    "# Evaluation:\n",
    "score = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy is: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
